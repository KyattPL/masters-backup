---
annotation-target: "[[gpt4_tech_report.pdf]]"
---


>%%
>```annotation-json
>{"created":"2024-04-26T15:13:35.038Z","updated":"2024-04-26T15:13:35.038Z","document":{"title":"gpt4_tech_report.pdf","link":[{"href":"urn:x-pdf:81f492d9158335464b99cce443d394e0"},{"href":"vault:/Papers PDFs/gpt4_tech_report.pdf"}],"documentFingerprint":"81f492d9158335464b99cce443d394e0"},"uri":"vault:/Papers PDFs/gpt4_tech_report.pdf","target":[{"source":"vault:/Papers PDFs/gpt4_tech_report.pdf","selector":[{"type":"TextPositionSelector","start":917,"end":1188},{"type":"TextQuoteSelector","exact":"This technical report presents GPT-4, a large multimodal model capable of processing image andtext inputs and producing text outputs. Such models are an important area of study as they have thepotential to be used in a wide range of applications, such as dialogue systems","prefix":"e compute ofGPT-4.1 Introduction","suffix":", text summarization,and machine"}]}]}
>```
>%%
>*%%PREFIX%%e compute ofGPT-4.1 Introduction%%HIGHLIGHT%% ==This technical report presents GPT-4, a large multimodal model capable of processing image andtext inputs and producing text outputs. Such models are an important area of study as they have thepotential to be used in a wide range of applications, such as dialogue systems== %%POSTFIX%%, text summarization,and machine*
>%%LINK%%[[#^c0go8pya7h5|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^c0go8pya7h5


>%%
>```annotation-json
>{"created":"2024-04-26T15:13:45.127Z","updated":"2024-04-26T15:13:45.127Z","document":{"title":"gpt4_tech_report.pdf","link":[{"href":"urn:x-pdf:81f492d9158335464b99cce443d394e0"},{"href":"vault:/Papers PDFs/gpt4_tech_report.pdf"}],"documentFingerprint":"81f492d9158335464b99cce443d394e0"},"uri":"vault:/Papers PDFs/gpt4_tech_report.pdf","target":[{"source":"vault:/Papers PDFs/gpt4_tech_report.pdf","selector":[{"type":"TextPositionSelector","start":1329,"end":1504},{"type":"TextQuoteSelector","exact":"One of the main goals of developing such models is to improve their ability to understand and generatenatural language text, particularly in more complex and nuanced scenarios","prefix":" progress inrecent years [1–34].","suffix":". To test its capabilitiesin suc"}]}]}
>```
>%%
>*%%PREFIX%%progress inrecent years [1–34].%%HIGHLIGHT%% ==One of the main goals of developing such models is to improve their ability to understand and generatenatural language text, particularly in more complex and nuanced scenarios== %%POSTFIX%%. To test its capabilitiesin suc*
>%%LINK%%[[#^p535x4pp2k|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^p535x4pp2k


>%%
>```annotation-json
>{"created":"2024-04-26T15:14:17.115Z","updated":"2024-04-26T15:14:17.115Z","document":{"title":"gpt4_tech_report.pdf","link":[{"href":"urn:x-pdf:81f492d9158335464b99cce443d394e0"},{"href":"vault:/Papers PDFs/gpt4_tech_report.pdf"}],"documentFingerprint":"81f492d9158335464b99cce443d394e0"},"uri":"vault:/Papers PDFs/gpt4_tech_report.pdf","target":[{"source":"vault:/Papers PDFs/gpt4_tech_report.pdf","selector":[{"type":"TextPositionSelector","start":2950,"end":3153},{"type":"TextQuoteSelector","exact":"Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [1, 37, 38]: it is not fullyreliable (e.g. can suffer from “hallucinations”), has a limited context window, and does not lear","prefix":"ease confidence in our training.","suffix":"n∗Please cite this work as “Open"}]}]}
>```
>%%
>*%%PREFIX%%ease confidence in our training.%%HIGHLIGHT%% ==Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [1, 37, 38]: it is not fullyreliable (e.g. can suffer from “hallucinations”), has a limited context window, and does not lear== %%POSTFIX%%n∗Please cite this work as “Open*
>%%LINK%%[[#^pg3cy0ccql|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^pg3cy0ccql


>%%
>```annotation-json
>{"created":"2024-04-26T15:14:23.994Z","updated":"2024-04-26T15:14:23.994Z","document":{"title":"gpt4_tech_report.pdf","link":[{"href":"urn:x-pdf:81f492d9158335464b99cce443d394e0"},{"href":"vault:/Papers PDFs/gpt4_tech_report.pdf"}],"documentFingerprint":"81f492d9158335464b99cce443d394e0"},"uri":"vault:/Papers PDFs/gpt4_tech_report.pdf","target":[{"source":"vault:/Papers PDFs/gpt4_tech_report.pdf","selector":[{"type":"TextPositionSelector","start":3395,"end":3519},{"type":"TextQuoteSelector","exact":"rom experience. Care should be taken when using the outputs of GPT-4, particularly in contextswhere reliability is important","prefix":"03.08774v6  [cs.CL]  4 Mar 2024f","suffix":".GPT-4’s capabilities and limita"}]}]}
>```
>%%
>*%%PREFIX%%03.08774v6  [cs.CL]  4 Mar 2024f%%HIGHLIGHT%% ==rom experience. Care should be taken when using the outputs of GPT-4, particularly in contextswhere reliability is important== %%POSTFIX%%.GPT-4’s capabilities and limita*
>%%LINK%%[[#^wpgjwv3uf3e|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^wpgjwv3uf3e


>%%
>```annotation-json
>{"created":"2024-04-26T15:14:43.117Z","updated":"2024-04-26T15:14:43.117Z","document":{"title":"gpt4_tech_report.pdf","link":[{"href":"urn:x-pdf:81f492d9158335464b99cce443d394e0"},{"href":"vault:/Papers PDFs/gpt4_tech_report.pdf"}],"documentFingerprint":"81f492d9158335464b99cce443d394e0"},"uri":"vault:/Papers PDFs/gpt4_tech_report.pdf","target":[{"source":"vault:/Papers PDFs/gpt4_tech_report.pdf","selector":[{"type":"TextPositionSelector","start":1506,"end":1724},{"type":"TextQuoteSelector","exact":"To test its capabilitiesin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. Inthese evaluations it performs quite well and often outscores the vast majority of human test takers","prefix":" complex and nuanced scenarios. ","suffix":".For example, on a simulated bar"}]}]}
>```
>%%
>*%%PREFIX%%complex and nuanced scenarios.%%HIGHLIGHT%% ==To test its capabilitiesin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. Inthese evaluations it performs quite well and often outscores the vast majority of human test takers== %%POSTFIX%%.For example, on a simulated bar*
>%%LINK%%[[#^igrfh4lejh|show annotation]]
>%%COMMENT%%
>
>%%TAGS%%
>
^igrfh4lejh
